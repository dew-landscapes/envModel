

  make_rf_quick <- function(x_df
                            , y_vec
                            , trees = 499
                            , cl_obj = NULL
                            , use_mtry
                            , do_imp = FALSE
                            ) {

    if(isTRUE(!is.null(cl_obj))) {

      rf_cores <- length(cl_obj)

      `%dopar%` <- foreach::`%dopar%`

      foreach::foreach(ntree = rep(ceiling(trees/rf_cores), rf_cores)
              , .combine = randomForest::combine
              , .packages = c("randomForest")
              ) %dopar%
        randomForest::randomForest(x = x_df
                                   , y = y_vec
                                   , importance = do_imp
                                   , mtry = use_mtry
                                   , ntree = ntree
                                   )

    } else {

      randomForest::randomForest(x = x_df
                                 , y = y_vec
                                 , importance = do_imp
                                 , mtry = use_mtry
                                 , ntree = trees
                                 )

    }

  }

#' Iteratively add trees to random forest until predictions stabilise
#'
#' @param env_df Dataframe with `clust_col`, `site_col` and columns `env_names`.
#' @param clust_col Character. Name of the columns with clusters.
#' @param env_names Character. Name of the environmental variables (e.g.
#' `names(stack_list)`).
#' @param trees_start Number of trees in first random forest run.
#' @param trees_add Number of trees to add in each subsequent run.
#' @param trees_max Maximum number of trees in the random forest.
#' @param rf_cores Number of cores to use for parallel processing.
#' @param use_mtry `mtry` value for [randomForest::randomForest()] call. If
#' `NULL` it will be generated by a (lengthy) call to [caret::train()]
#' with a tune grid of `.mtry = 1:floor(sqrt(length(env_names))`.
#' @param set_min FALSE or numeric. If numeric, classes in `clust_col` with less
#' @param accept_delta What proportion change between runs is acceptable?
#' @param accept_run How many forests (in a row) need to beat `accept_delta`?
#' @param internal_metrics TRUE or test data in same format as `env_df`.
#' @param do_imp Logical. Passed to `importance` argument of
#' [randomForest::randomForest()].
#' @param keep_rf Logical. If true, `randomForest` object will be included in
#' output. Defaults to `FALSE` to save memory.
#' @param out_file Optional name of file to save results.
#' @param do_gc Logical. Run `gc()` when results are available and all other
#' objects have been removed.
#'
#' @return
#' @export
#'
#' @examples
  make_rf_good <- function(env_df
                           , clust_col = "cluster"
                           , env_names
                           , trees_start = 499
                           , trees_add = 249
                           , trees_max = 9999
                           , rf_cores = 1
                           , use_mtry = NULL
                           , set_min = FALSE
                           , accept_delta = 0.995
                           , accept_run = 3
                           , internal_metrics = TRUE
                           , do_imp = FALSE
                           , keep_rf = FALSE
                           , out_file = NULL
                           , do_gc = TRUE
                           ) {

    .do_imp = do_imp

    go_time <- Sys.time()

    if(isTRUE(!is.null(out_file))) {

      out_file <- gsub("\\.*$","",out_file)
      out_file <- paste0(out_file,".rds")

    }

    if(!isFALSE(set_min)) {

      env_df <- env_df %>%
        dplyr::add_count(!!rlang::ensym(clust_col)) %>%
        dplyr::filter(n > set_min) %>%
        dplyr::select(-n) %>%
        dplyr::mutate(!!clust_col := factor(!!rlang::ensym(clust_col)))

    }

    x <- env_df[,which(names(env_df) %in% env_names)]
    y <- env_df[clust_col][[1]] %>% factor()

    rf_good <- list()

    # setup parallel cluster
    if(rf_cores > 1) {

      cl <- parallel::makePSOCKcluster(rf_cores)
      doParallel::registerDoParallel(cl)

    }

    if(isTRUE(is.null(use_mtry))) {

      # Training control for caret implementation of machine learning methods
      ctrl <- caret::trainControl(method = "cv"
                                  , savePredictions = FALSE
                                  , verboseIter = FALSE
                                  , allowParallel = rf_cores > 1
                                  )

      # Tuning grid
      c_tune_grid <- expand.grid(.mtry = 1:floor(sqrt(length(env_names))))

      rf_good$mtry <- caret::train(x
                                      , y
                                      , method = "rf"
                                      , trControl = ctrl
                                      , tuneGrid = c_tune_grid
                                      , metric = "Kappa"
                                      , trace = FALSE
                                      )

      rf_good$mtry <- rf_good$mtry %>%
        `[[` ("finalModel") %>%
        `[[` ("mtry")

      } else rf_good$mtry <- use_mtry


    get_truth_pred <- function(int_met, rf){

      if(isTRUE(int_met)) {

        truth <- y
        pred <- rf$predicted


      } else {

        new_data <- int_met[, env_names]

        truth <- int_met[clust_col][[1]]

        pred <- predict(rf, newdata = new_data)

      }

      tibble::tibble(truth,pred)

    }

    rf <- make_rf_quick(x
                        , y
                        , trees = trees_start
                        , if(rf_cores > 1) cl_obj = cl
                        , use_mtry = rf_good$mtry
                        , do_imp = .do_imp
                        )

    metrics <- get_conf_metrics(get_truth_pred(internal_metrics
                                               , rf
                                               )
                                )

    if(keep_rf) rf_good$rf <- rf

    rf_good$rf_res <- tibble::tibble(trees = trees_start) %>%
      dplyr::mutate(metrics = list(metrics)
                    , ntree = rf$ntree
                    ) %>%
      tidyr::unnest(cols = c(metrics)) %>%
      dplyr::mutate(prev_kappa = kap
                    , prev_delta = kap
                    )

    counter <- 0

    while(
      as.logical(
        (counter < accept_run) *
        (rf_good$rf_res$ntree[[nrow(rf_good$rf_res)]] < trees_max)
      )
    ) {

      prev_rf <- if(exists("new_rf")) new_rf else rf

      next_rf <- make_rf_quick(x
                               , y
                               , trees = trees_add
                               , if(rf_cores > 1) cl_obj = cl
                               , use_mtry = rf_good$mtry
                              , do_imp = .do_imp
                               )

      new_rf <- randomForest::combine(prev_rf,next_rf)

      metrics <- get_conf_metrics(get_truth_pred(internal_metrics
                                                  , new_rf
                                                  )
                                   )

      prev_delta <- sum(prev_rf$predicted == new_rf$predicted)/length(y)

      prev_kappa <- yardstick::kap(tibble::tibble(truth = prev_rf$predicted
                                         , estimate = new_rf$predicted
                                         )
                                  , truth
                                  , estimate
                                  )$.estimate

      if(keep_rf) rf_good$rf <- new_rf

      rf_good$rf_res <- tibble::tibble(prev_delta = prev_delta
                                       , prev_kappa = prev_kappa
                                       , ntree = new_rf$ntree
                                       ) %>%
                           dplyr::bind_cols(metrics)

      counter <- if(prev_delta >= accept_delta) {

        counter + 1

        } else 0


      cat(
        paste0("ntree: ", rf_good$rf_res$rf[[nrow(rf_good$rf_res)]]$ntree
              , "\n counter on: ", counter, " (Stop at ",accept_run,")"
               , "\n kappa: ",round(rf_good$rf_res$kap[[nrow(rf_good$rf_res)]],4)
               , "\n changed predictions: ",paste0(round(100-100*rf_good$rf_res$prev_delta[nrow(rf_good$rf_res)],3),"%")
               , "\n kappa based on confusion with last run: ", round(rf_good$rf_res$prev_kappa[[nrow(rf_good$rf_res)]],4)
               , "\n elapsed time: ", as.numeric(round(difftime(Sys.time(), go_time, units = "secs"),2)), " seconds\n\n"
               )
      )

    }

    # stop parallel cluster
    if(rf_cores > 1) {

      parallel::stopCluster(cl)
      rm(cl)

    }

    rf_good$metrics <- if(isTRUE(internal_metrics)) "internal" else "test data"

    rf_good$seconds <- round(as.numeric(difftime(Sys.time(), go_time, units = "secs")),2)

    if(!isTRUE(is.null(out_file))) rio::export(rf_good, out_file)

    stuff <- ls() %>% grep("rf_good", ., value = TRUE, invert = TRUE)

    rm(list = stuff)

    if(do_gc) gc()

    return(rf_good)

  }



